{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02: Feature Extraction avec ResNet\n",
    "\n",
    "Ce notebook démontre l'extraction de features à partir d'images IRM cérébrales en utilisant un modèle ResNet50 pré-entraîné.\n",
    "\n",
    "## Objectifs\n",
    "1. Charger et pré-traiter les images IRM\n",
    "2. Extraire des features avec ResNet50\n",
    "3. Visualiser les embeddings dans un espace réduit\n",
    "4. Préparer les données pour le clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from src.model.features import FeatureExtractor\n",
    "from src.model.preprocessing import ImagePreprocessor\n",
    "from src.data.loader import DataLoaderWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = Path(\"../data\")\n",
    "MODEL_NAME = \"resnet50\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des composants\n",
    "preprocessor = ImagePreprocessor()\n",
    "feature_extractor = FeatureExtractor(model_name=MODEL_NAME, device=DEVICE)\n",
    "data_loader = DataLoaderWrapper(DATA_DIR)\n",
    "\n",
    "# Découverte des images\n",
    "image_paths = data_loader.discover_images()\n",
    "print(f\"Nombre d'images trouvées: {len(image_paths)}\")\n",
    "\n",
    "# Limiter à un sous-ensemble pour les tests\n",
    "if len(image_paths) > 100:\n",
    "    image_paths = image_paths[:100]\n",
    "    print(f\"Utilisation d'un sous-ensemble de {len(image_paths)} images pour les tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extraction des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des features\n",
    "print(\"Début de l'extraction des features...\")\n",
    "features = feature_extractor.extract_features_from_paths(\n",
    "    image_paths=image_paths,\n",
    "    preprocessor=preprocessor,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(f\"Shape des features: {features.shape}\")\n",
    "print(f\"Dimension des features: {features.shape[1]}\")\n",
    "\n",
    "# Sauvegarde des features\n",
    "features_path = DATA_DIR / \"features_resnet50.npy\"\n",
    "np.save(features_path, features)\n",
    "print(f\"Features sauvegardées dans: {features_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse statistique des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "print(\"\\nStatistiques des features:\")\n",
    "print(features_df.describe().T[['mean', 'std', 'min', 'max']].head(10))\n",
    "\n",
    "# Visualisation des distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Distribution des premières dimensions\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i < features.shape[1]:\n",
    "        ax.hist(features[:, i], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        ax.set_title(f\"Distribution de la feature {i}\")\n",
    "        ax.set_xlabel(\"Valeur\")\n",
    "        ax.set_ylabel(\"Fréquence\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Réduction de dimensionnalité pour visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# PCA pour réduction à 2D\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "features_pca = pca.fit_transform(features)\n",
    "\n",
    "# t-SNE pour visualisation\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(features)-1))\n",
    "features_tsne = tsne.fit_transform(features)\n",
    "\n",
    "print(f\"Variance expliquée par PCA: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "print(f\"Variance expliquée par composante 1: {pca.explained_variance_ratio_[0]:.2%}\")\n",
    "print(f\"Variance expliquée par composante 2: {pca.explained_variance_ratio_[1]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation PCA\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(features_pca[:, 0], features_pca[:, 1], alpha=0.6, s=20)\n",
    "plt.title(\"PCA des features ResNet50\")\n",
    "plt.xlabel(\"Composante principale 1\")\n",
    "plt.ylabel(\"Composante principale 2\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Visualisation t-SNE\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(features_tsne[:, 0], features_tsne[:, 1], alpha=0.6, s=20)\n",
    "plt.title(\"t-SNE des features ResNet50\")\n",
    "plt.xlabel(\"t-SNE dimension 1\")\n",
    "plt.ylabel(\"t-SNE dimension 2\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse de similarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calcul de la matrice de similarité cosinus\n",
    "similarity_matrix = cosine_similarity(features)\n",
    "\n",
    "# Visualisation de la matrice de similarité\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(similarity_matrix, cmap='viridis', aspect='auto')\n",
    "plt.colorbar(label='Similarité cosinus')\n",
    "plt.title('Matrice de similarité entre images')\n",
    "plt.xlabel('Index image')\n",
    "plt.ylabel('Index image')\n",
    "plt.show()\n",
    "\n",
    "# Statistiques de similarité\n",
    "similarity_values = similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)]\n",
    "print(f\"\\nStatistiques de similarité:\")\n",
    "print(f\"Moyenne: {similarity_values.mean():.3f}\")\n",
    "print(f\"Écart-type: {similarity_values.std():.3f}\")\n",
    "print(f\"Min: {similarity_values.min():.3f}\")\n",
    "print(f\"Max: {similarity_values.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Préparation pour le clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des données pour le clustering\n",
    "import pickle\n",
    "\n",
    "clustering_data = {\n",
    "    'features': features,\n",
    "    'image_paths': [str(p) for p in image_paths],\n",
    "    'features_pca': features_pca,\n",
    "    'features_tsne': features_tsne,\n",
    "    'similarity_matrix': similarity_matrix\n",
    "}\n",
    "\n",
    "clustering_path = DATA_DIR / \"clustering_data.pkl\"\n",
    "with open(clustering_path, 'wb') as f:\n",
    "    pickle.dump(clustering_data, f)\n",
    "\n",
    "print(f\"Données pour clustering sauvegardées dans: {clustering_path}\")\n",
    "print(f\"Taille des features: {features.shape}\")\n",
    "print(f\"Nombre d'images: {len(image_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Résumé et prochaines étapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== RÉSUMÉ DE L'EXTRACTION DE FEATURES ===\")\n",
    "print(f\"Modèle utilisé: {MODEL_NAME}\")\n",
    "print(f\"Nombre d'images traitées: {len(image_paths)}\")\n",
    "print(f\"Dimension des features: {features.shape[1]}\")\n",
    "print(f\"Variance expliquée par PCA (2D): {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "print(f\"Similarité moyenne entre images: {similarity_values.mean():.3f}\")\n",
    "print(\"\\nProchaines étapes:\")\n",
    "print(\"1. Appliquer le clustering (K-Means, DBSCAN) sur les features\")\n",
    "print(\"2. Générer des labels faibles à partir des clusters\")\n",
    "print(\"3. Visualiser les clusters dans l'espace réduit\")\n",
    "print(\"4. Évaluer la qualité du clustering avec métriques de silhouette\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tests unitaires intégrés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests de validation\n",
    "def test_feature_extraction():\n",
    "    \"\"\"Test basique de l'extraction de features.\"\"\"\n",
    "    assert features.shape[0] == len(image_paths), \"Nombre de features doit correspondre au nombre d'images\"\n",
    "    assert features.shape[1] == feature_extractor.feature_dim, \"Dimension des features incorrecte\"\n",
    "    assert not np.any(np.isnan(features)), \"Les features ne doivent pas contenir de NaN\"\n",
    "    assert not np.any(np.isinf(features)), \"Les features ne doivent pas contenir d'infini\"\n",
    "    print(\"✅ Tests de validation des features réussis\")\n",
    "\n",
    "test_feature_extraction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}